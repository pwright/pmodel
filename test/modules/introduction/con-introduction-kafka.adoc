[id="introduction-kafka"]
= What is {product}?
:imagesdir: ../../_images

[role="_abstract"]
{product-long} is a cloud service that simplifies the process of running Apache Kafka.
Apache Kafka is an open-source, distributed, publish-subscribe messaging system for creating fault-tolerant, real-time data feeds.

Your {org-name} account gives you access to {product}.
Within minutes, you’ll have a Kafka instance up and running, and be ready to start defining the Kafka configuration you need.

== Understanding Kafka instances

A Kafka instance comprises a Kafka cluster with multiple brokers. Brokers contain topics that receive and store data.
Topics are split by partitions, which are distributed and replicated across brokers for fault tolerance and increased throughput.

To understand how a Kafka instance operates as a message broker, it’s important to understand the key concepts described here.

Kafka cluster::
A Kafka cluster is a group of Kafka brokers, ZooKeeper instances, and management components.
Broker::
A broker, sometimes referred to as a server or node, contains topics and orchestrates the storage and passing of messages.
Topic::
A topic provides a destination for the storage of data. Each topic is split into one or more partitions.
Partition::
A partition is a subset of a topic. Partitions are used for data sharding and replication. The number of topic partitions is defined by a topic partition count.
Partition leader::
A partition leader handles all producer requests for a given partition.
Partition follower::
A partition follower replicates the partition data of a partition leader, optionally handling consumer requests.
Replication factor::
Topics use a replication factor to configure the number of replicas of each partition within the cluster.
A topic comprises at least one partition. In {product}, the replication factor is 3.
In-sync replicas::
Kafka elects a partition leader to handle all producer requests for a partition.
Partition followers on other brokers replicate the partition data of the partition leader.
Each in-sync replica has the same number of messages as the leader. If the leader partition fails, Kafka chooses an in-sync replica as the new leader.

In your configuration, you can define how many replicas must be in sync to be able to produce messages.
A message is committed only after it’s been successfully copied to the replica partition. In this way, if the leader fails, the message is not lost.

In {product}, the minimum number of in-sync replicas is 2.
Here we can see in the diagram that each numbered partition has a leader and two followers in replicated topics.

.Kafka topics with replicated partitions
image::introduction/160_OpenShift_Streams_Apache_Kafka_0421_brokers_topics.svg[Image of Kafka cluster with replicated partitions]

== Kafka producers and consumers

Producers and consumers send and receive (publish and subscribe) messages through Kafka brokers.
Apache Kafka clients act as producers, consumers, or both.

Producer::
A producer sends messages to a broker topic to be written to a partition.
Messages are written to partitions either on a round-robin basis or to a specific partition based on a message key.
A round-robin approach distributes messages equally across partitions.
Consumer::
A consumer subscribes to a topic and reads messages according to partition and offset.
Consumer group::
Consumer groups are typically used to share a large data stream generated by multiple producers from a given topic.
Consumers are grouped using a group ID, allowing messages to be spread across the members.
Consumers within a group don’t read data from the same partition, but can receive data from one or more partitions.
+
.Producers and consumers interacting with the Kafka broker
image::introduction/160_OpenShift_Streams_Apache_Kafka_0421_producer_consumer.svg[Image of Kafka producers and consumers interacting with Kafka]

Offsets::
Offsets allow consumers to track their position in each partition. Each message in a given partition has a unique offset. Offsets help identify the position of a consumer within the partition to track the number of records that have been consumed.
+
The producer offset at the head of the partition shows the read position. The consumer offset position shows the write position.
+
.Producing and consuming data from a partition
image::introduction/160_OpenShift_Streams_Apache_Kafka_0421_producer_consumer_data.svg[Image of Kafka producers and consumers writing and reading using offsets]
+
When a record is consumed, the consumer’s position in the partition is updated by committing an offset.
Kafka’s __consumer_offsets topic stores information on the latest committed offset for each partition according to the consumer group.

== Kafka capabilities

Kafka’s underlying data stream-processing capabilities and component architecture delivers the following key capabilities:

* Extremely high throughput and low latency data sharing between microservices and other applications
* Message ordering guarantees
* Message rewind/replay from data storage to reconstruct an application state
* Message compaction using keys to identify messages and retain only the most recent
* Horizontal scalability in a cluster configuration
* Replication of data to control fault tolerance
* Retention of high volumes of data for immediate access

== Kafka use cases

Kafka’s capabilities make it suitable for the following use cases:

* Event-driven architectures
* Event sourcing to capture changes to the state of an application as a log of events
* Message brokering
* Website activity tracking
* Operational monitoring through metrics
* Log collection and aggregation
* Commit logs for distributed systems
* Stream processing so that applications can respond to data in real time

[role="_additional-resources"]
.Additional resources
* link:https://kafka.apache.org/[Apache Kafka^]
